{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# My seed\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (42000, 784)\n",
      "Shape of y_train: (42000,)\n",
      "Shape of X_test : (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test\n",
    "\n",
    "# Free memory space\n",
    "\n",
    "del df_train\n",
    "del df_test\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of X_test :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 4684,\n",
       "         0: 4132,\n",
       "         4: 4072,\n",
       "         7: 4401,\n",
       "         3: 4351,\n",
       "         5: 3795,\n",
       "         8: 4063,\n",
       "         9: 4188,\n",
       "         2: 4177,\n",
       "         6: 4137})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the values of training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the images in 3 dimensions to use with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (42000, 28, 28, 1)\n",
      "Shape of X_test : (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1) # (height = 28px, width = 28px , canal = 1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_test :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting y values (labels) to categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Categories\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the baseline neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \n",
    "    # Create baseline\n",
    "    \n",
    "    baseline = Sequential()\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # 32 filters for the two firsts conv2D layers\n",
    "    \n",
    "    baseline.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', \n",
    "                     input_shape = (28, 28, 1)))\n",
    "    baseline.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "    \n",
    "    # This layer simply acts as a downsampling filter. \n",
    "    # It looks at the 2 neighboring pixels and picks the maximal value, reducing computational cost, \n",
    "    # and to some extent also reduce overfitting.\n",
    "    \n",
    "    # IMPORTANT: Combining convolutional and pooling layers, CNN are able to combine local features and \n",
    "    # learn more global features of the image.\n",
    "    \n",
    "    baseline.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Dropout is a regularization method, where a proportion of nodes (25%) in the layer are randomly ignored \n",
    "    # for each training sample. This dropout forces the network to learn features in a distributed way \n",
    "    # and improves generalization and reduces the overfitting.\n",
    "    \n",
    "    baseline.add(Dropout(0.25))\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # 64 filters for the two last conv2D layers\n",
    "    \n",
    "    baseline.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "    baseline.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "    \n",
    "    baseline.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    baseline.add(Dropout(0.25))\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # The Flatten layer is use to convert the final feature maps into a one single 1D vector. \n",
    "    # IMPORTANT: It combines all the found local features of the previous convolutional layers.\n",
    "    \n",
    "    baseline.add(Flatten())\n",
    "    baseline.add(Dense(256, activation = \"relu\"))\n",
    "    baseline.add(Dropout(0.5))\n",
    "    \n",
    "    # The net outputs distribution of probability of each class --> In our case, 10 output classes\n",
    "    \n",
    "    baseline.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    # The optimizer will iteratively improve parameters in order to minimize the loss.\n",
    "    \n",
    "    optimizer = RMSprop(epsilon=1e-08)\n",
    "\n",
    "    # Compile the baseline including the optimizer and evaluating the performance of the baseline by accuracy\n",
    "    \n",
    "    baseline.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If after the third epoch we didn't have an improvement of accuracy, the learning rate will be \n",
    "# reduced by 50% (factor).\n",
    "\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                 patience=3, \n",
    "                                 verbose=0, \n",
    "                                 factor=0.5, \n",
    "                                 min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea is to alter the training data with small transformations to reproduce the variations \n",
    "# occuring when someone is writing a digit. It's a way to minimize the overfitting of the model.\n",
    "\n",
    "generator = ImageDataGenerator(featurewise_center = False,\n",
    "                               samplewise_center = False, \n",
    "                               featurewise_std_normalization = False,\n",
    "                               samplewise_std_normalization = False,\n",
    "                               zca_whitening = False,\n",
    "                               rotation_range = 15, # Rotate image in 15 degrees\n",
    "                               zoom_range = 0.15, # Zoom image (15% zoom) \n",
    "                               width_shift_range = 0.15, # Shift image horizontally (15% of width)\n",
    "                               height_shift_range = 0.15, # Shift image vertically (15% of height)\n",
    "                               horizontal_flip = False,\n",
    "                               vertical_flip = False)\n",
    "\n",
    "generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 10 nets and training every ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 10\n",
    "digits = [0] * nets\n",
    "history = [0] * nets\n",
    "\n",
    "epochs = 45\n",
    "batch_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.6024 - acc: 0.8051 - val_loss: 0.1117 - val_acc: 0.9664\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.1798 - acc: 0.9462 - val_loss: 0.0520 - val_acc: 0.9821\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.1239 - acc: 0.9628 - val_loss: 0.0447 - val_acc: 0.9867\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.1029 - acc: 0.9698 - val_loss: 0.0315 - val_acc: 0.9883\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0897 - acc: 0.9738 - val_loss: 0.0425 - val_acc: 0.9888\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 235s 561ms/step - loss: 0.0856 - acc: 0.9756 - val_loss: 0.0355 - val_acc: 0.9893\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0806 - acc: 0.9762 - val_loss: 0.0426 - val_acc: 0.9902\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0804 - acc: 0.9775 - val_loss: 0.0411 - val_acc: 0.9881\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 235s 561ms/step - loss: 0.0766 - acc: 0.9792 - val_loss: 0.0262 - val_acc: 0.9907\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0737 - acc: 0.9793 - val_loss: 0.0276 - val_acc: 0.9921\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 235s 561ms/step - loss: 0.0766 - acc: 0.9797 - val_loss: 0.0329 - val_acc: 0.9890\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0792 - acc: 0.9782 - val_loss: 0.0358 - val_acc: 0.9914\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 234s 558ms/step - loss: 0.0781 - acc: 0.9794 - val_loss: 0.0348 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 241s 573ms/step - loss: 0.0594 - acc: 0.9832 - val_loss: 0.0285 - val_acc: 0.9924\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0576 - acc: 0.9839 - val_loss: 0.0251 - val_acc: 0.9943\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0562 - acc: 0.9848 - val_loss: 0.0338 - val_acc: 0.9902\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0586 - acc: 0.9842 - val_loss: 0.0350 - val_acc: 0.9905\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0571 - acc: 0.9854 - val_loss: 0.0327 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0484 - acc: 0.9867 - val_loss: 0.0235 - val_acc: 0.9940\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0485 - acc: 0.9872 - val_loss: 0.0294 - val_acc: 0.9929\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0516 - acc: 0.9864 - val_loss: 0.0296 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 239s 569ms/step - loss: 0.0446 - acc: 0.9880 - val_loss: 0.0232 - val_acc: 0.9938\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.0438 - acc: 0.9879 - val_loss: 0.0259 - val_acc: 0.9943\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0432 - acc: 0.9878 - val_loss: 0.0217 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0431 - acc: 0.9890 - val_loss: 0.0240 - val_acc: 0.9940\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 246s 586ms/step - loss: 0.0406 - acc: 0.9884 - val_loss: 0.0241 - val_acc: 0.9945\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 250s 596ms/step - loss: 0.0388 - acc: 0.9896 - val_loss: 0.0226 - val_acc: 0.9952\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0383 - acc: 0.9894 - val_loss: 0.0221 - val_acc: 0.9943\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0396 - acc: 0.9888 - val_loss: 0.0247 - val_acc: 0.9945\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0389 - acc: 0.9894 - val_loss: 0.0239 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0396 - acc: 0.9889 - val_loss: 0.0230 - val_acc: 0.9945\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0408 - acc: 0.9894 - val_loss: 0.0222 - val_acc: 0.9948\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0393 - acc: 0.9891 - val_loss: 0.0225 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0387 - acc: 0.9891 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0391 - acc: 0.9895 - val_loss: 0.0226 - val_acc: 0.9948\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0377 - acc: 0.9898 - val_loss: 0.0223 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0380 - acc: 0.9895 - val_loss: 0.0219 - val_acc: 0.9945\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0376 - acc: 0.9893 - val_loss: 0.0218 - val_acc: 0.9945\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 234s 558ms/step - loss: 0.0390 - acc: 0.9890 - val_loss: 0.0225 - val_acc: 0.9943\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.0235 - val_acc: 0.9945\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0404 - acc: 0.9887 - val_loss: 0.0222 - val_acc: 0.9945\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0390 - acc: 0.9893 - val_loss: 0.0222 - val_acc: 0.9945\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0389 - acc: 0.9893 - val_loss: 0.0216 - val_acc: 0.9943\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0376 - acc: 0.9889 - val_loss: 0.0221 - val_acc: 0.9945\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0381 - acc: 0.9889 - val_loss: 0.0219 - val_acc: 0.9948\n",
      "CNN Model 1: Epochs = 45, Train accuracy = 0.98981, Validation accuracy = 0.99524\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.6045 - acc: 0.8003 - val_loss: 0.0688 - val_acc: 0.9800\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.1768 - acc: 0.9467 - val_loss: 0.0511 - val_acc: 0.9845\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.1248 - acc: 0.9624 - val_loss: 0.0356 - val_acc: 0.9898\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.1068 - acc: 0.9685 - val_loss: 0.0351 - val_acc: 0.9900\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0919 - acc: 0.9724 - val_loss: 0.0310 - val_acc: 0.9917\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0870 - acc: 0.9744 - val_loss: 0.0276 - val_acc: 0.9914\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0791 - acc: 0.9766 - val_loss: 0.0249 - val_acc: 0.9929\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0790 - acc: 0.9771 - val_loss: 0.0546 - val_acc: 0.9843\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0763 - acc: 0.9771 - val_loss: 0.0253 - val_acc: 0.9929\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0754 - acc: 0.9788 - val_loss: 0.0299 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0588 - acc: 0.9828 - val_loss: 0.0207 - val_acc: 0.9929\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 241s 575ms/step - loss: 0.0612 - acc: 0.9829 - val_loss: 0.0235 - val_acc: 0.9929\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 241s 575ms/step - loss: 0.0564 - acc: 0.9838 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0572 - acc: 0.9838 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0584 - acc: 0.9839 - val_loss: 0.0220 - val_acc: 0.9936\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 241s 575ms/step - loss: 0.0610 - acc: 0.9836 - val_loss: 0.0217 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 242s 575ms/step - loss: 0.0500 - acc: 0.9853 - val_loss: 0.0202 - val_acc: 0.9948\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0482 - acc: 0.9863 - val_loss: 0.0163 - val_acc: 0.9945\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 241s 575ms/step - loss: 0.0487 - acc: 0.9858 - val_loss: 0.0183 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 242s 575ms/step - loss: 0.0425 - acc: 0.9886 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0424 - acc: 0.9884 - val_loss: 0.0149 - val_acc: 0.9952\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0449 - acc: 0.9874 - val_loss: 0.0149 - val_acc: 0.9940\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 242s 575ms/step - loss: 0.0428 - acc: 0.9879 - val_loss: 0.0162 - val_acc: 0.9948\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0438 - acc: 0.9875 - val_loss: 0.0171 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0406 - acc: 0.9887 - val_loss: 0.0144 - val_acc: 0.9948\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0371 - acc: 0.9888 - val_loss: 0.0151 - val_acc: 0.9943\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0417 - acc: 0.9884 - val_loss: 0.0160 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0375 - acc: 0.9893 - val_loss: 0.0149 - val_acc: 0.9950\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0379 - acc: 0.9893 - val_loss: 0.0149 - val_acc: 0.9950\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0373 - acc: 0.9891 - val_loss: 0.0149 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0400 - acc: 0.9885 - val_loss: 0.0141 - val_acc: 0.9950\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0383 - acc: 0.9888 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0390 - acc: 0.9891 - val_loss: 0.0142 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0362 - acc: 0.9897 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0359 - acc: 0.9895 - val_loss: 0.0147 - val_acc: 0.9955\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 235s 559ms/step - loss: 0.0410 - acc: 0.9882 - val_loss: 0.0147 - val_acc: 0.9955\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 235s 560ms/step - loss: 0.0379 - acc: 0.9889 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 241s 574ms/step - loss: 0.0400 - acc: 0.9886 - val_loss: 0.0139 - val_acc: 0.9950\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0393 - acc: 0.9894 - val_loss: 0.0145 - val_acc: 0.9952\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0383 - acc: 0.9894 - val_loss: 0.0143 - val_acc: 0.9950\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0394 - acc: 0.9884 - val_loss: 0.0146 - val_acc: 0.9952\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0405 - acc: 0.9892 - val_loss: 0.0144 - val_acc: 0.9955\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0388 - acc: 0.9892 - val_loss: 0.0144 - val_acc: 0.9950\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0393 - acc: 0.9890 - val_loss: 0.0144 - val_acc: 0.9948\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0379 - acc: 0.9886 - val_loss: 0.0142 - val_acc: 0.9950\n",
      "CNN Model 2: Epochs = 45, Train accuracy = 0.98971, Validation accuracy = 0.99548\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.5911 - acc: 0.8103 - val_loss: 0.0878 - val_acc: 0.9719\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.1743 - acc: 0.9490 - val_loss: 0.0410 - val_acc: 0.9888\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.1258 - acc: 0.9623 - val_loss: 0.0378 - val_acc: 0.9886\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.1050 - acc: 0.9695 - val_loss: 0.0261 - val_acc: 0.9914\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0943 - acc: 0.9723 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0855 - acc: 0.9752 - val_loss: 0.0346 - val_acc: 0.9898\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0805 - acc: 0.9764 - val_loss: 0.0244 - val_acc: 0.9948\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0777 - acc: 0.9788 - val_loss: 0.0319 - val_acc: 0.9895\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0820 - acc: 0.9776 - val_loss: 0.0253 - val_acc: 0.9943\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0741 - acc: 0.9791 - val_loss: 0.0263 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0594 - acc: 0.9833 - val_loss: 0.0250 - val_acc: 0.9943\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0558 - acc: 0.9839 - val_loss: 0.0181 - val_acc: 0.9940\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0542 - acc: 0.9853 - val_loss: 0.0192 - val_acc: 0.9960\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0557 - acc: 0.9847 - val_loss: 0.0265 - val_acc: 0.9926\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0554 - acc: 0.9846 - val_loss: 0.0240 - val_acc: 0.9943\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 249s 592ms/step - loss: 0.0560 - acc: 0.9840 - val_loss: 0.0231 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 257s 613ms/step - loss: 0.0482 - acc: 0.9870 - val_loss: 0.0171 - val_acc: 0.9955\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 246s 586ms/step - loss: 0.0488 - acc: 0.9857 - val_loss: 0.0197 - val_acc: 0.9952\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0483 - acc: 0.9864 - val_loss: 0.0184 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0419 - acc: 0.9878 - val_loss: 0.0170 - val_acc: 0.9964\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0417 - acc: 0.9879 - val_loss: 0.0183 - val_acc: 0.9960\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0404 - acc: 0.9882 - val_loss: 0.0169 - val_acc: 0.9962\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0411 - acc: 0.9886 - val_loss: 0.0194 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0427 - acc: 0.9884 - val_loss: 0.0166 - val_acc: 0.9957\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0403 - acc: 0.9882 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0378 - acc: 0.9893 - val_loss: 0.0169 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0366 - acc: 0.9889 - val_loss: 0.0164 - val_acc: 0.9962\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 242s 575ms/step - loss: 0.0388 - acc: 0.9887 - val_loss: 0.0160 - val_acc: 0.9957\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.0166 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0371 - acc: 0.9893 - val_loss: 0.0161 - val_acc: 0.9960\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0346 - acc: 0.9901 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0379 - acc: 0.9893 - val_loss: 0.0163 - val_acc: 0.9964\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0365 - acc: 0.9897 - val_loss: 0.0166 - val_acc: 0.9960\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0375 - acc: 0.9897 - val_loss: 0.0165 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0374 - acc: 0.9894 - val_loss: 0.0165 - val_acc: 0.9960\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 248s 590ms/step - loss: 0.0386 - acc: 0.9889 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0377 - acc: 0.9891 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0366 - acc: 0.9901 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0366 - acc: 0.9898 - val_loss: 0.0158 - val_acc: 0.9962\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0365 - acc: 0.9894 - val_loss: 0.0159 - val_acc: 0.9964\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0371 - acc: 0.9897 - val_loss: 0.0158 - val_acc: 0.9967\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0359 - acc: 0.9900 - val_loss: 0.0162 - val_acc: 0.9967\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0364 - acc: 0.9897 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0352 - acc: 0.9900 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0363 - acc: 0.9898 - val_loss: 0.0165 - val_acc: 0.9960\n",
      "CNN Model 3: Epochs = 45, Train accuracy = 0.99013, Validation accuracy = 0.99690\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.6022 - acc: 0.8041 - val_loss: 0.0734 - val_acc: 0.9807\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.1798 - acc: 0.9472 - val_loss: 0.0504 - val_acc: 0.9850\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.1277 - acc: 0.9620 - val_loss: 0.0529 - val_acc: 0.9843\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.1047 - acc: 0.9699 - val_loss: 0.0264 - val_acc: 0.9912\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0934 - acc: 0.9727 - val_loss: 0.0325 - val_acc: 0.9898\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0873 - acc: 0.9747 - val_loss: 0.0284 - val_acc: 0.9910\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0827 - acc: 0.9758 - val_loss: 0.0338 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0611 - acc: 0.9816 - val_loss: 0.0220 - val_acc: 0.9917\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0635 - acc: 0.9823 - val_loss: 0.0183 - val_acc: 0.9938\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0627 - acc: 0.9827 - val_loss: 0.0223 - val_acc: 0.9933\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0623 - acc: 0.9820 - val_loss: 0.0233 - val_acc: 0.9929\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0580 - acc: 0.9828 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0496 - acc: 0.9858 - val_loss: 0.0168 - val_acc: 0.9945\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0228 - val_acc: 0.9938\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0475 - acc: 0.9856 - val_loss: 0.0215 - val_acc: 0.9936\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0492 - acc: 0.9857 - val_loss: 0.0157 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0445 - acc: 0.9871 - val_loss: 0.0164 - val_acc: 0.9945\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0415 - acc: 0.9881 - val_loss: 0.0171 - val_acc: 0.9945\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0422 - acc: 0.9880 - val_loss: 0.0152 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0423 - acc: 0.9880 - val_loss: 0.0152 - val_acc: 0.9950\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0415 - acc: 0.9879 - val_loss: 0.0158 - val_acc: 0.9945\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0159 - val_acc: 0.9948\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0406 - acc: 0.9883 - val_loss: 0.0169 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0383 - acc: 0.9887 - val_loss: 0.0157 - val_acc: 0.9950\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0401 - acc: 0.9885 - val_loss: 0.0162 - val_acc: 0.9945\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0400 - acc: 0.9886 - val_loss: 0.0156 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0402 - acc: 0.9883 - val_loss: 0.0158 - val_acc: 0.9948\n",
      "Epoch 28/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.0151 - val_acc: 0.9950\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0407 - acc: 0.9887 - val_loss: 0.0148 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0365 - acc: 0.9892 - val_loss: 0.0157 - val_acc: 0.9948\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0384 - acc: 0.9890 - val_loss: 0.0153 - val_acc: 0.9952\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0353 - acc: 0.9896 - val_loss: 0.0153 - val_acc: 0.9948\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.0154 - val_acc: 0.9948\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0378 - acc: 0.9891 - val_loss: 0.0155 - val_acc: 0.9950\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0381 - acc: 0.9888 - val_loss: 0.0157 - val_acc: 0.9948\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0408 - acc: 0.9885 - val_loss: 0.0154 - val_acc: 0.9948\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0370 - acc: 0.9888 - val_loss: 0.0155 - val_acc: 0.9948\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0375 - acc: 0.9895 - val_loss: 0.0153 - val_acc: 0.9948\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0356 - acc: 0.9900 - val_loss: 0.0156 - val_acc: 0.9950\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 246s 585ms/step - loss: 0.0371 - acc: 0.9893 - val_loss: 0.0160 - val_acc: 0.9950\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0360 - acc: 0.9897 - val_loss: 0.0157 - val_acc: 0.9948\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0404 - acc: 0.9886 - val_loss: 0.0161 - val_acc: 0.9945\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0385 - acc: 0.9890 - val_loss: 0.0159 - val_acc: 0.9950\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0381 - acc: 0.9891 - val_loss: 0.0159 - val_acc: 0.9948\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0371 - acc: 0.9890 - val_loss: 0.0160 - val_acc: 0.9948\n",
      "CNN Model 4: Epochs = 45, Train accuracy = 0.99003, Validation accuracy = 0.99524\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.5858 - acc: 0.8096 - val_loss: 0.0673 - val_acc: 0.9790\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.1763 - acc: 0.9469 - val_loss: 0.0638 - val_acc: 0.9810\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.1268 - acc: 0.9634 - val_loss: 0.0499 - val_acc: 0.9857\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.1056 - acc: 0.9693 - val_loss: 0.0324 - val_acc: 0.9905\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0954 - acc: 0.9725 - val_loss: 0.0350 - val_acc: 0.9876\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0864 - acc: 0.9746 - val_loss: 0.0326 - val_acc: 0.9893\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0822 - acc: 0.9763 - val_loss: 0.0428 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0627 - acc: 0.9818 - val_loss: 0.0289 - val_acc: 0.9933\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0597 - acc: 0.9822 - val_loss: 0.0216 - val_acc: 0.9936\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0599 - acc: 0.9824 - val_loss: 0.0248 - val_acc: 0.9933\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0596 - acc: 0.9832 - val_loss: 0.0260 - val_acc: 0.9931\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0587 - acc: 0.9832 - val_loss: 0.0236 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0503 - acc: 0.9855 - val_loss: 0.0244 - val_acc: 0.9924\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0483 - acc: 0.9859 - val_loss: 0.0241 - val_acc: 0.9936\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0448 - acc: 0.9863 - val_loss: 0.0226 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0442 - acc: 0.9876 - val_loss: 0.0206 - val_acc: 0.9940\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0436 - acc: 0.9874 - val_loss: 0.0212 - val_acc: 0.9938\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0412 - acc: 0.9878 - val_loss: 0.0207 - val_acc: 0.9943\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0417 - acc: 0.9879 - val_loss: 0.0224 - val_acc: 0.9938\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0452 - acc: 0.9874 - val_loss: 0.0227 - val_acc: 0.9938\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0432 - acc: 0.9870 - val_loss: 0.0204 - val_acc: 0.9950\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0423 - acc: 0.9874 - val_loss: 0.0234 - val_acc: 0.9945\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0401 - acc: 0.9886 - val_loss: 0.0241 - val_acc: 0.9943\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0424 - acc: 0.9879 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0397 - acc: 0.9887 - val_loss: 0.0193 - val_acc: 0.9950\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0399 - acc: 0.9890 - val_loss: 0.0205 - val_acc: 0.9943\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0394 - acc: 0.9886 - val_loss: 0.0195 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0403 - acc: 0.9892 - val_loss: 0.0203 - val_acc: 0.9943\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0196 - val_acc: 0.9952\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0367 - acc: 0.9893 - val_loss: 0.0189 - val_acc: 0.9948\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0355 - acc: 0.9890 - val_loss: 0.0208 - val_acc: 0.9948\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0379 - acc: 0.9901 - val_loss: 0.0201 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0375 - acc: 0.9892 - val_loss: 0.0203 - val_acc: 0.9948\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0371 - acc: 0.9893 - val_loss: 0.0199 - val_acc: 0.9945\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0378 - acc: 0.9893 - val_loss: 0.0202 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0365 - acc: 0.9892 - val_loss: 0.0208 - val_acc: 0.9940\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0365 - acc: 0.9897 - val_loss: 0.0205 - val_acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.0209 - val_acc: 0.9940\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0364 - acc: 0.9894 - val_loss: 0.0204 - val_acc: 0.9945\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0368 - acc: 0.9895 - val_loss: 0.0200 - val_acc: 0.9943\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0382 - acc: 0.9892 - val_loss: 0.0200 - val_acc: 0.9945\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0366 - acc: 0.9895 - val_loss: 0.0199 - val_acc: 0.9945\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0365 - acc: 0.9898 - val_loss: 0.0197 - val_acc: 0.9945\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0375 - acc: 0.9893 - val_loss: 0.0199 - val_acc: 0.9945\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0383 - acc: 0.9895 - val_loss: 0.0195 - val_acc: 0.9948\n",
      "CNN Model 5: Epochs = 45, Train accuracy = 0.99005, Validation accuracy = 0.99524\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.6358 - acc: 0.7938 - val_loss: 0.0699 - val_acc: 0.9755\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.1917 - acc: 0.9424 - val_loss: 0.0561 - val_acc: 0.9819\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.1361 - acc: 0.9599 - val_loss: 0.0486 - val_acc: 0.9864\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.1102 - acc: 0.9672 - val_loss: 0.0297 - val_acc: 0.9910\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0996 - acc: 0.9707 - val_loss: 0.0279 - val_acc: 0.9902\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0902 - acc: 0.9738 - val_loss: 0.0287 - val_acc: 0.9919\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 243s 577ms/step - loss: 0.0819 - acc: 0.9765 - val_loss: 0.0489 - val_acc: 0.9850\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0853 - acc: 0.9759 - val_loss: 0.0263 - val_acc: 0.9929\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0818 - acc: 0.9763 - val_loss: 0.0352 - val_acc: 0.9910\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0794 - acc: 0.9783 - val_loss: 0.0409 - val_acc: 0.9902\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0824 - acc: 0.9775 - val_loss: 0.0333 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0615 - acc: 0.9824 - val_loss: 0.0227 - val_acc: 0.9938\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0615 - acc: 0.9838 - val_loss: 0.0232 - val_acc: 0.9936\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0619 - acc: 0.9828 - val_loss: 0.0201 - val_acc: 0.9945\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0638 - acc: 0.9831 - val_loss: 0.0201 - val_acc: 0.9945\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0629 - acc: 0.9830 - val_loss: 0.0219 - val_acc: 0.9945\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0630 - acc: 0.9828 - val_loss: 0.0278 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0560 - acc: 0.9847 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0520 - acc: 0.9858 - val_loss: 0.0217 - val_acc: 0.9948\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0507 - acc: 0.9855 - val_loss: 0.0228 - val_acc: 0.9948\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0482 - acc: 0.9875 - val_loss: 0.0241 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0467 - acc: 0.9877 - val_loss: 0.0207 - val_acc: 0.9943\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0441 - acc: 0.9874 - val_loss: 0.0202 - val_acc: 0.9952\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0472 - acc: 0.9873 - val_loss: 0.0184 - val_acc: 0.9960\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 240s 570ms/step - loss: 0.0446 - acc: 0.9879 - val_loss: 0.0201 - val_acc: 0.9952\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0433 - acc: 0.9872 - val_loss: 0.0194 - val_acc: 0.9952\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0508 - acc: 0.9867 - val_loss: 0.0204 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0438 - acc: 0.9879 - val_loss: 0.0214 - val_acc: 0.9948\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0423 - acc: 0.9879 - val_loss: 0.0197 - val_acc: 0.9948\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0430 - acc: 0.9884 - val_loss: 0.0184 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0424 - acc: 0.9884 - val_loss: 0.0193 - val_acc: 0.9948\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0430 - acc: 0.9883 - val_loss: 0.0202 - val_acc: 0.9950\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0408 - acc: 0.9885 - val_loss: 0.0190 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0400 - acc: 0.9894 - val_loss: 0.0194 - val_acc: 0.9955\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0372 - acc: 0.9900 - val_loss: 0.0194 - val_acc: 0.9955\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0405 - acc: 0.9887 - val_loss: 0.0200 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0426 - acc: 0.9880 - val_loss: 0.0198 - val_acc: 0.9952\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 246s 585ms/step - loss: 0.0399 - acc: 0.9894 - val_loss: 0.0199 - val_acc: 0.9950\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0422 - acc: 0.9887 - val_loss: 0.0194 - val_acc: 0.9952\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0402 - acc: 0.9894 - val_loss: 0.0194 - val_acc: 0.9955\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0429 - acc: 0.9886 - val_loss: 0.0193 - val_acc: 0.9950\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 239s 569ms/step - loss: 0.0425 - acc: 0.9876 - val_loss: 0.0192 - val_acc: 0.9955\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0405 - acc: 0.9891 - val_loss: 0.0193 - val_acc: 0.9952\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.0403 - acc: 0.9896 - val_loss: 0.0188 - val_acc: 0.9955\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0414 - acc: 0.9884 - val_loss: 0.0188 - val_acc: 0.9957\n",
      "CNN Model 6: Epochs = 45, Train accuracy = 0.99000, Validation accuracy = 0.99595\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.6003 - acc: 0.8032 - val_loss: 0.0700 - val_acc: 0.9790\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.1790 - acc: 0.9469 - val_loss: 0.0551 - val_acc: 0.9824\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 236s 561ms/step - loss: 0.1316 - acc: 0.9610 - val_loss: 0.0481 - val_acc: 0.9862\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.1057 - acc: 0.9684 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0965 - acc: 0.9722 - val_loss: 0.0598 - val_acc: 0.9817\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0868 - acc: 0.9738 - val_loss: 0.0347 - val_acc: 0.9900\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0822 - acc: 0.9761 - val_loss: 0.0400 - val_acc: 0.9902\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0799 - acc: 0.9771 - val_loss: 0.0326 - val_acc: 0.9912\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0766 - acc: 0.9789 - val_loss: 0.0342 - val_acc: 0.9914\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0777 - acc: 0.9788 - val_loss: 0.0429 - val_acc: 0.9888\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0773 - acc: 0.9784 - val_loss: 0.0329 - val_acc: 0.9926\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0765 - acc: 0.9789 - val_loss: 0.0342 - val_acc: 0.9912\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0759 - acc: 0.9788 - val_loss: 0.0492 - val_acc: 0.9876\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0796 - acc: 0.9794 - val_loss: 0.0411 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0635 - acc: 0.9830 - val_loss: 0.0277 - val_acc: 0.9929\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0602 - acc: 0.9837 - val_loss: 0.0279 - val_acc: 0.9929\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0558 - acc: 0.9846 - val_loss: 0.0319 - val_acc: 0.9924\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0624 - acc: 0.9839 - val_loss: 0.0315 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0502 - acc: 0.9860 - val_loss: 0.0274 - val_acc: 0.9940\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0506 - acc: 0.9866 - val_loss: 0.0315 - val_acc: 0.9940\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0508 - acc: 0.9863 - val_loss: 0.0314 - val_acc: 0.9924\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0490 - acc: 0.9868 - val_loss: 0.0292 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0463 - acc: 0.9876 - val_loss: 0.0288 - val_acc: 0.9936\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0463 - acc: 0.9867 - val_loss: 0.0302 - val_acc: 0.9931\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0471 - acc: 0.9870 - val_loss: 0.0306 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0421 - acc: 0.9887 - val_loss: 0.0303 - val_acc: 0.9931\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0414 - acc: 0.9883 - val_loss: 0.0311 - val_acc: 0.9929\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0426 - acc: 0.9882 - val_loss: 0.0318 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0419 - acc: 0.9887 - val_loss: 0.0296 - val_acc: 0.9933\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0434 - acc: 0.9885 - val_loss: 0.0314 - val_acc: 0.9931\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0399 - acc: 0.9889 - val_loss: 0.0301 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0391 - acc: 0.9889 - val_loss: 0.0304 - val_acc: 0.9931\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0402 - acc: 0.9886 - val_loss: 0.0301 - val_acc: 0.9933\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0395 - acc: 0.9891 - val_loss: 0.0306 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0402 - acc: 0.9893 - val_loss: 0.0311 - val_acc: 0.9933\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0421 - acc: 0.9882 - val_loss: 0.0300 - val_acc: 0.9938\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0419 - acc: 0.9882 - val_loss: 0.0304 - val_acc: 0.9936\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0407 - acc: 0.9888 - val_loss: 0.0305 - val_acc: 0.9933\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0416 - acc: 0.9894 - val_loss: 0.0302 - val_acc: 0.9938\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0396 - acc: 0.9889 - val_loss: 0.0307 - val_acc: 0.9938\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0439 - acc: 0.9881 - val_loss: 0.0298 - val_acc: 0.9936\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0411 - acc: 0.9884 - val_loss: 0.0308 - val_acc: 0.9936\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0415 - acc: 0.9889 - val_loss: 0.0305 - val_acc: 0.9938\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.0300 - val_acc: 0.9936\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0401 - acc: 0.9891 - val_loss: 0.0301 - val_acc: 0.9936\n",
      "CNN Model 7: Epochs = 45, Train accuracy = 0.98944, Validation accuracy = 0.99405\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.5845 - acc: 0.8116 - val_loss: 0.0870 - val_acc: 0.9714\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.1709 - acc: 0.9496 - val_loss: 0.0575 - val_acc: 0.9800\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.1188 - acc: 0.9636 - val_loss: 0.0339 - val_acc: 0.9895\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.1020 - acc: 0.9706 - val_loss: 0.0362 - val_acc: 0.9886\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0903 - acc: 0.9737 - val_loss: 0.0382 - val_acc: 0.9890\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0831 - acc: 0.9759 - val_loss: 0.0308 - val_acc: 0.9914\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0784 - acc: 0.9768 - val_loss: 0.0357 - val_acc: 0.9900\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0791 - acc: 0.9767 - val_loss: 0.0295 - val_acc: 0.9921\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0799 - acc: 0.9781 - val_loss: 0.0390 - val_acc: 0.9890\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0764 - acc: 0.9787 - val_loss: 0.0305 - val_acc: 0.9912\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0746 - acc: 0.9803 - val_loss: 0.0395 - val_acc: 0.9926\n",
      "Epoch 12/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0776 - acc: 0.9801 - val_loss: 0.0381 - val_acc: 0.9912\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0765 - acc: 0.9797 - val_loss: 0.0322 - val_acc: 0.9924\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 243s 578ms/step - loss: 0.0791 - acc: 0.9796 - val_loss: 0.0317 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0618 - acc: 0.9838 - val_loss: 0.0285 - val_acc: 0.9955\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 246s 585ms/step - loss: 0.0606 - acc: 0.9842 - val_loss: 0.0263 - val_acc: 0.9940\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0610 - acc: 0.9849 - val_loss: 0.0273 - val_acc: 0.9921\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0623 - acc: 0.9829 - val_loss: 0.0284 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0523 - acc: 0.9860 - val_loss: 0.0237 - val_acc: 0.9938\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0514 - acc: 0.9859 - val_loss: 0.0282 - val_acc: 0.9938\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 248s 591ms/step - loss: 0.0512 - acc: 0.9868 - val_loss: 0.0232 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0467 - acc: 0.9874 - val_loss: 0.0251 - val_acc: 0.9950\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0425 - acc: 0.9885 - val_loss: 0.0269 - val_acc: 0.9940\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0447 - acc: 0.9883 - val_loss: 0.0273 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0447 - acc: 0.9880 - val_loss: 0.0238 - val_acc: 0.9945\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0397 - acc: 0.9888 - val_loss: 0.0258 - val_acc: 0.9945\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0423 - acc: 0.9882 - val_loss: 0.0256 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 237s 563ms/step - loss: 0.0424 - acc: 0.9888 - val_loss: 0.0243 - val_acc: 0.9945\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0410 - acc: 0.9886 - val_loss: 0.0245 - val_acc: 0.9945\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0441 - acc: 0.9878 - val_loss: 0.0250 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0392 - acc: 0.9893 - val_loss: 0.0245 - val_acc: 0.9948\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0405 - acc: 0.9888 - val_loss: 0.0247 - val_acc: 0.9940\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0418 - acc: 0.9885 - val_loss: 0.0252 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 247s 588ms/step - loss: 0.0387 - acc: 0.9893 - val_loss: 0.0249 - val_acc: 0.9945\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0383 - acc: 0.9895 - val_loss: 0.0250 - val_acc: 0.9945\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 246s 586ms/step - loss: 0.0398 - acc: 0.9889 - val_loss: 0.0245 - val_acc: 0.9943\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0427 - acc: 0.9884 - val_loss: 0.0246 - val_acc: 0.9940\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 310s 739ms/step - loss: 0.0396 - acc: 0.9885 - val_loss: 0.0247 - val_acc: 0.9945\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 399s 950ms/step - loss: 0.0402 - acc: 0.9887 - val_loss: 0.0244 - val_acc: 0.9945\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 387s 921ms/step - loss: 0.0400 - acc: 0.9896 - val_loss: 0.0252 - val_acc: 0.9945\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 242s 576ms/step - loss: 0.0384 - acc: 0.9895 - val_loss: 0.0248 - val_acc: 0.9945\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.0385 - acc: 0.9897 - val_loss: 0.0245 - val_acc: 0.9950\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0394 - acc: 0.9896 - val_loss: 0.0245 - val_acc: 0.9943\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.0426 - acc: 0.9881 - val_loss: 0.0252 - val_acc: 0.9945\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.0401 - acc: 0.9892 - val_loss: 0.0246 - val_acc: 0.9940\n",
      "CNN Model 8: Epochs = 45, Train accuracy = 0.98971, Validation accuracy = 0.99548\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 240s 570ms/step - loss: 0.5549 - acc: 0.8192 - val_loss: 0.0621 - val_acc: 0.9802\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - 240s 572ms/step - loss: 0.1685 - acc: 0.9506 - val_loss: 0.0525 - val_acc: 0.9850\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.1258 - acc: 0.9620 - val_loss: 0.0521 - val_acc: 0.9843\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0989 - acc: 0.9704 - val_loss: 0.0341 - val_acc: 0.9910\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 246s 585ms/step - loss: 0.0927 - acc: 0.9726 - val_loss: 0.0378 - val_acc: 0.9900\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0852 - acc: 0.9754 - val_loss: 0.0388 - val_acc: 0.9898\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 240s 571ms/step - loss: 0.0812 - acc: 0.9762 - val_loss: 0.0325 - val_acc: 0.9919\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.0768 - acc: 0.9780 - val_loss: 0.0306 - val_acc: 0.9912\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0736 - acc: 0.9786 - val_loss: 0.0308 - val_acc: 0.9919\n",
      "Epoch 10/45\n",
      "420/420 [==============================] - 238s 568ms/step - loss: 0.0790 - acc: 0.9780 - val_loss: 0.0338 - val_acc: 0.9921\n",
      "Epoch 11/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0763 - acc: 0.9790 - val_loss: 0.0351 - val_acc: 0.9933\n",
      "Epoch 12/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0786 - acc: 0.9784 - val_loss: 0.0378 - val_acc: 0.9919\n",
      "Epoch 13/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0771 - acc: 0.9796 - val_loss: 0.0330 - val_acc: 0.9931\n",
      "Epoch 14/45\n",
      "420/420 [==============================] - 237s 563ms/step - loss: 0.0742 - acc: 0.9796 - val_loss: 0.0331 - val_acc: 0.9936\n",
      "Epoch 15/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0750 - acc: 0.9796 - val_loss: 0.0295 - val_acc: 0.9931\n",
      "Epoch 16/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0751 - acc: 0.9790 - val_loss: 0.0321 - val_acc: 0.9919\n",
      "Epoch 17/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0735 - acc: 0.9801 - val_loss: 0.0345 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 18/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0578 - acc: 0.9853 - val_loss: 0.0383 - val_acc: 0.9929\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0607 - acc: 0.9830 - val_loss: 0.0342 - val_acc: 0.9919\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 240s 571ms/step - loss: 0.0580 - acc: 0.9842 - val_loss: 0.0285 - val_acc: 0.9940\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0566 - acc: 0.9842 - val_loss: 0.0374 - val_acc: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0603 - acc: 0.9833 - val_loss: 0.0293 - val_acc: 0.9933\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 243s 579ms/step - loss: 0.0583 - acc: 0.9846 - val_loss: 0.0336 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 243s 580ms/step - loss: 0.0481 - acc: 0.9866 - val_loss: 0.0295 - val_acc: 0.9936\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0495 - acc: 0.9860 - val_loss: 0.0324 - val_acc: 0.9919\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0477 - acc: 0.9868 - val_loss: 0.0304 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 247s 587ms/step - loss: 0.0442 - acc: 0.9880 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 246s 585ms/step - loss: 0.0443 - acc: 0.9878 - val_loss: 0.0311 - val_acc: 0.9924\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 240s 571ms/step - loss: 0.0402 - acc: 0.9890 - val_loss: 0.0302 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0391 - acc: 0.9887 - val_loss: 0.0293 - val_acc: 0.9933\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0394 - acc: 0.9888 - val_loss: 0.0305 - val_acc: 0.9938\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0382 - acc: 0.9887 - val_loss: 0.0315 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0394 - acc: 0.9891 - val_loss: 0.0303 - val_acc: 0.9931\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 237s 563ms/step - loss: 0.0375 - acc: 0.9890 - val_loss: 0.0297 - val_acc: 0.9933\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 236s 563ms/step - loss: 0.0383 - acc: 0.9890 - val_loss: 0.0289 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 239s 569ms/step - loss: 0.0375 - acc: 0.9901 - val_loss: 0.0295 - val_acc: 0.9936\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0368 - acc: 0.9896 - val_loss: 0.0294 - val_acc: 0.9933\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 245s 584ms/step - loss: 0.0404 - acc: 0.9889 - val_loss: 0.0286 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0393 - acc: 0.9893 - val_loss: 0.0292 - val_acc: 0.9938\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 238s 568ms/step - loss: 0.0410 - acc: 0.9889 - val_loss: 0.0300 - val_acc: 0.9936\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0375 - acc: 0.9892 - val_loss: 0.0295 - val_acc: 0.9938\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 238s 566ms/step - loss: 0.0365 - acc: 0.9897 - val_loss: 0.0304 - val_acc: 0.9936\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0362 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9931\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 237s 563ms/step - loss: 0.0373 - acc: 0.9894 - val_loss: 0.0302 - val_acc: 0.9933\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 236s 562ms/step - loss: 0.0354 - acc: 0.9898 - val_loss: 0.0302 - val_acc: 0.9933\n",
      "CNN Model 9: Epochs = 45, Train accuracy = 0.99008, Validation accuracy = 0.99405\n",
      "Epoch 1/45\n",
      "420/420 [==============================] - 242s 577ms/step - loss: 0.5686 - acc: 0.8186 - val_loss: 0.1473 - val_acc: 0.9560\n",
      "Epoch 2/45\n",
      "420/420 [==============================] - -3363s -8007909us/step - loss: 0.1800 - acc: 0.9454 - val_loss: 0.0734 - val_acc: 0.9810\n",
      "Epoch 3/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.1189 - acc: 0.9656 - val_loss: 0.0497 - val_acc: 0.9855\n",
      "Epoch 4/45\n",
      "420/420 [==============================] - 240s 572ms/step - loss: 0.1027 - acc: 0.9704 - val_loss: 0.0341 - val_acc: 0.9895\n",
      "Epoch 5/45\n",
      "420/420 [==============================] - 237s 565ms/step - loss: 0.0932 - acc: 0.9729 - val_loss: 0.0409 - val_acc: 0.9895\n",
      "Epoch 6/45\n",
      "420/420 [==============================] - 240s 571ms/step - loss: 0.0832 - acc: 0.9758 - val_loss: 0.0335 - val_acc: 0.9900\n",
      "Epoch 7/45\n",
      "420/420 [==============================] - 237s 564ms/step - loss: 0.0778 - acc: 0.9776 - val_loss: 0.0437 - val_acc: 0.9881\n",
      "Epoch 8/45\n",
      "420/420 [==============================] - 238s 567ms/step - loss: 0.0746 - acc: 0.9781 - val_loss: 0.0331 - val_acc: 0.9895\n",
      "Epoch 9/45\n",
      "420/420 [==============================] - 239s 570ms/step - loss: 0.0699 - acc: 0.9802 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/45\n",
      " 45/420 [==>...........................] - ETA: 3:24 - loss: 0.0505 - acc: 0.9832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 237s 563ms/step - loss: 0.0412 - acc: 0.9883 - val_loss: 0.0258 - val_acc: 0.9924\n",
      "Epoch 19/45\n",
      "420/420 [==============================] - 241s 575ms/step - loss: 0.0404 - acc: 0.9881 - val_loss: 0.0264 - val_acc: 0.9914\n",
      "Epoch 20/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0368 - acc: 0.9896 - val_loss: 0.0245 - val_acc: 0.9917\n",
      "Epoch 22/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0379 - acc: 0.9890 - val_loss: 0.0250 - val_acc: 0.9921\n",
      "Epoch 23/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0354 - acc: 0.9899 - val_loss: 0.0258 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 24/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0355 - acc: 0.9901 - val_loss: 0.0243 - val_acc: 0.9917\n",
      "Epoch 25/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0365 - acc: 0.9897 - val_loss: 0.0249 - val_acc: 0.9919\n",
      "Epoch 26/45\n",
      "420/420 [==============================] - 244s 580ms/step - loss: 0.0353 - acc: 0.9901 - val_loss: 0.0240 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0367 - acc: 0.9896 - val_loss: 0.0234 - val_acc: 0.9921\n",
      "Epoch 28/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0350 - acc: 0.9899 - val_loss: 0.0235 - val_acc: 0.9919\n",
      "Epoch 29/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0359 - acc: 0.9894 - val_loss: 0.0243 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 30/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0349 - acc: 0.9900 - val_loss: 0.0244 - val_acc: 0.9919\n",
      "Epoch 31/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0349 - acc: 0.9899 - val_loss: 0.0248 - val_acc: 0.9914\n",
      "Epoch 32/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0322 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9919\n",
      "Epoch 33/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0331 - acc: 0.9901 - val_loss: 0.0251 - val_acc: 0.9919\n",
      "Epoch 34/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0372 - acc: 0.9900 - val_loss: 0.0248 - val_acc: 0.9917\n",
      "Epoch 35/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0333 - acc: 0.9902 - val_loss: 0.0249 - val_acc: 0.9917\n",
      "Epoch 36/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0344 - acc: 0.9903 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 37/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0345 - acc: 0.9902 - val_loss: 0.0247 - val_acc: 0.9917\n",
      "Epoch 38/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0335 - acc: 0.9898 - val_loss: 0.0246 - val_acc: 0.9912\n",
      "Epoch 39/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0329 - acc: 0.9903 - val_loss: 0.0238 - val_acc: 0.9919\n",
      "Epoch 40/45\n",
      "420/420 [==============================] - 245s 583ms/step - loss: 0.0340 - acc: 0.9900 - val_loss: 0.0238 - val_acc: 0.9924\n",
      "Epoch 41/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0318 - acc: 0.9906 - val_loss: 0.0244 - val_acc: 0.9924\n",
      "Epoch 42/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0354 - acc: 0.9902 - val_loss: 0.0236 - val_acc: 0.9924\n",
      "Epoch 43/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0370 - acc: 0.9894 - val_loss: 0.0236 - val_acc: 0.9929\n",
      "Epoch 44/45\n",
      "420/420 [==============================] - 244s 582ms/step - loss: 0.0362 - acc: 0.9900 - val_loss: 0.0238 - val_acc: 0.9921\n",
      "Epoch 45/45\n",
      "420/420 [==============================] - 244s 581ms/step - loss: 0.0340 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9921\n",
      "CNN Model 10: Epochs = 45, Train accuracy = 0.99066, Validation accuracy = 0.99286\n"
     ]
    }
   ],
   "source": [
    "for model in range(nets):\n",
    "    digits[model] = baseline_model()\n",
    "    \n",
    "    # Splitting train and test datasets\n",
    "    \n",
    "    X_train_aux, X_test_aux, y_train_aux, y_test_aux = train_test_split(X_train, y_train, test_size = 0.1)\n",
    "    \n",
    "    history[model] = digits[model].fit_generator(generator.flow(X_train_aux,\n",
    "                                                              y_train_aux, \n",
    "                                                              batch_size = batch_size),\n",
    "                                                 epochs = epochs, \n",
    "                                                 steps_per_epoch = X_train_aux.shape[0] // batch_size, \n",
    "                                                 validation_data = (X_test_aux, y_test_aux), \n",
    "                                                 callbacks=[lr_reduction],\n",
    "                                                 verbose=1)\n",
    "    \n",
    "    print(\"CNN Model {0:d}: Epochs = {1:d}, Train accuracy = {2:.5f}, Validation accuracy = {3:.5f}\".format(\n",
    "        model + 1, # Number of the CNN model\n",
    "        epochs, # Total of epochs\n",
    "        max(history[model].history['acc']), # Maximum Accuracy from Training\n",
    "        max(history[model].history['val_acc']))) # Maximum Accuracy from Test (validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the predictions with more probabilities to be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predicted = np.zeros( (X_test.shape[0], 10) ) \n",
    "\n",
    "for model in range(nets):\n",
    "    label_predicted = label_predicted + digits[model].predict(X_test)\n",
    "    \n",
    "# Get the index with the maximum probability\n",
    "\n",
    "label_predicted = np.argmax(label_predicted, axis = 1)\n",
    "label_predicted = pd.Series(label_predicted, name = \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.concat([pd.Series(range(1, 28001), name = \"ImageId\"), label_predicted], axis = 1)\n",
    "solution.to_csv(\"solution_cnn_v5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in range(nets):\n",
    "    model_saved = digits[model].to_json()\n",
    "    name = 'model_' + str(model) + '.json'\n",
    "    with open(name, 'w') as json_file:\n",
    "        json_file.write(model_saved)\n",
    "    name = 'model_' + str(model) + '.h5'\n",
    "    digits[model].save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = [0] * nets\n",
    "for model in range(nets):\n",
    "    name = 'model_' + str(model) + '.json'\n",
    "    json_file = open(name, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model_loaded[model] = model_from_json(loaded_model_json)\n",
    "    name = 'model_' + str(model) + '.h5'\n",
    "    model_loaded[model].load_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
